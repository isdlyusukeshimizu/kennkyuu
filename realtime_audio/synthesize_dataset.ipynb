{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow\n",
    "\n",
    "Dummy personal information (label/ground truth) -> Hiragana Pronunciation -> Phrase -> Audio file\n",
    "\n",
    "# Usage\n",
    "\n",
    "1. Generate the dummy personal information csv: https://testdata.userlocal.jp/.\n",
    "2. Get an elevenlabs API Key for `.env` (can use a free account): https://elevenlabs.io/app/settings/api-keys\n",
    "3. Configure the label column.\n",
    "4. Modify the pronunciation -> phrase template as needed.\n",
    "5. Run the notebook. It takes about 0.6 second per file.\n",
    "\n",
    "Note userlocal purports to generate data by the ENTIRE demographic of Japan. So if our client's customer bas a different demographic(e.g. the elderly in the small towns), we may need to resample to match.\n",
    "\n",
    "## Changing the voice\n",
    "This is configured with `voice_id`. See https://elevenlabs.io/app/voice-library. Note some voices may not be compatible with your model of choice.\n",
    "\n",
    "## Sound not being articulated correctly\n",
    "I would try modifying the label -> pronunciation template. If that did not help, might need to fiddle with the `convert()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import wave\n",
    "\n",
    "import pandas as pd\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from jinja2 import Template\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ut.aoai import gpt_call\n",
    "from ut.para import process_list_in_parallel\n",
    "\n",
    "client = ElevenLabs()\n",
    "\n",
    "folder = \"data/phone\"\n",
    "clear = True  # DELETES EVERYTHING in the folder first. For debugging\n",
    "samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"氏名\",\"氏名（ひらがな）\",\"年齢\",\"生年月日\",\"性別\",\n",
    "# \"血液型\",\"メールアドレス\",\"電話番号\",\"携帯電話番号\",\n",
    "# \"郵便番号\",\"住所\",\"会社名\",\"クレジットカード\",\"有効期限\",\"マイナンバー\"\n",
    "df = pd.read_csv(\"dummy.csv\")\n",
    "sample = df.sample(samples)[\"電話番号\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert text to its pronunciation.\n",
    "# Elevenlab's model does not seem to know how to pronunce certain kanji/phone numbers,\n",
    "# Names of places can be tricky in Japanese too,\n",
    "# So we're giving it some help with LLM.\n",
    "\n",
    "template = Template(\n",
    "  \"\"\"Convert the following japanese text into how it would be pronunced in hiragana. \n",
    "Insert half-width spaces if there would be a short pause.\n",
    "\n",
    "{{address}}\"\"\"\n",
    ")\n",
    "\n",
    "converted = process_list_in_parallel(lambda x: gpt_call(template.render(address=x)), sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this instead of setting previous_text, next_text from convert()\n",
    "# Produces more natural results.\n",
    "\n",
    "phrase = Template(\"\"\"電話番号は {{address}} です。\"\"\")\n",
    "converted = [phrase.render(address=x) for x in converted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(folder):\n",
    "  os.makedirs(folder)\n",
    "\n",
    "if clear:\n",
    "  for file in os.listdir(folder):\n",
    "    os.remove(f\"{folder}/{file}\")\n",
    "\n",
    "for label, pronunciation in tqdm(list(zip(sample, converted))):\n",
    "  try:\n",
    "    audio = client.text_to_speech.convert(\n",
    "      text=pronunciation,\n",
    "      voice_id=\"3JDquces8E8bkmvbh6Bc\",\n",
    "      model_id=\"eleven_flash_v2_5\",\n",
    "      output_format=\"pcm_16000\",  # https://github.com/elevenlabs/elevenlabs-python/blob/main/src/elevenlabs/types/output_format.py\n",
    "      language_code=\"ja\",  # https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes\n",
    "    )\n",
    "\n",
    "    with wave.open(f\"{folder}/{label}.wav\", \"wb\") as wav_file:\n",
    "      # these values need to be set as there's no default.\n",
    "      wav_file.setnchannels(1)\n",
    "      wav_file.setsampwidth(2)\n",
    "      wav_file.setframerate(16000)\n",
    "      for chunk in audio:\n",
    "        wav_file.writeframes(chunk)\n",
    "  except Exception as e:\n",
    "    print(f\"Failed to generate audio for {label}: {e}\")\n",
    "    traceback.print_exc()\n",
    "    continue  # sometimes the remote will have a random error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
